{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 梯度下降算法\n",
    "## 复习一个简单感知机的机制"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img alt=\"image\" width=\"900\" height=\"300\" src=\"http://wp.lampta.com:8000/wp-content/uploads/2022/02/image-45.png\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "上图是一个简单的感知机，从这个感知机可以分析权重是如何被调整的\n",
    "\n",
    "1、X1作为输入值，被赋予了一个权重W1\n",
    "2、然后输入经过激活函数，计算除了y-hat\n",
    "3、再来将y-hat与实际值y进行比较，使用损失函数协方差，计算出损失值C\n",
    "\n",
    "那么问题就是，如何获取到最小损失？ 也就是C最小"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 简单匹配法求最小损失函数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们知道，不同的权重值, Wn 得到的结果与真实结果的差异是不同的，也就是损失函数值不同。\n",
    "那么我们直接用各种权重去实验，是可以得到一个最小的C的\n",
    "\n",
    "比如我们有1000个权重值，我们用这一千个权重值，去实验，得到一千个C值，如下图所示："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image](http://wp.lampta.com:8000/wp-content/uploads/2022/02/image-46-1024x487.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "根据图示，我们知道，最小的C是最底部的那个值："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image](http://wp.lampta.com:8000/wp-content/uploads/2022/02/image-47.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 为何不能采用简单匹配法？"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "随着你的权重值数目的增加，你的神经网络突触也会成几何倍数增长，如果你使用简单匹配法，你将不得不面对“维数灾难”"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 以房价估值为例来说明为什么会遇到\"维数灾难\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 已经训练好的房屋估价神经网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img height=\"488\" src=\"http://wp.lampta.com:8000/wp-content/uploads/2022/02/image-48-1024x651.png\" width=\"768\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 未训练的房屋估价神经网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img height=\"488\" src=\"http://wp.lampta.com:8000/wp-content/uploads/2022/02/image-49-1024x660.png\" width=\"768\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到已经训练好的模型，突触要比未训练的模型少，这是因为训练好的模型，把对输入值无关紧要的权重去除掉了。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "未经训练的网络里，共有25个权重((4个输入值*5个神经元) + 5个输出值)\n",
    "利用简单匹配算法，对于每个权重，假设我们有1000个值需要实验，总的组合数，就是1000的25次方\n",
    "\n",
    "1000 * 1000 * ... * 1000 = 1000^25 = 10^75\n",
    "\n",
    "这个数值，使用太湖之光(每秒93兆次的算力：93 * (10^15)) 来计算，那么需要 10^75 / (93 * 10^15)秒 = 3.42 * (10^50) 年\n",
    "\n",
    "这还只是一个简单的神经网络, 如果类似以下这种稍微有点复杂的神经网络呢:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](http://wp.lampta.com:8000/wp-content/uploads/2022/02/image-50.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用梯度下降来寻找最优权重"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "首先我们假设一个损失函数解集如图所示:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](http://wp.lampta.com:8000/wp-content/uploads/2022/02/image-51.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1、首先从图中某个点开始(相当于赋予一个初始权重)，对那个点的函数求导(导数的几何意义是该函数曲线在这一点上的切线斜率), 找到该点的斜率(slope)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image](http://wp.lampta.com:8000/wp-content/uploads/2022/02/grad.gif)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果该斜率为负数,意味着你需要向右寻找\n",
    "如果斜率为正, 意味着你需要向左寻找\n",
    "直到你找到了最优权重\n",
    "当然，不可能向gif里如此平滑，整个过程就如下图所示:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image](http://wp.lampta.com:8000/wp-content/uploads/2022/02/image-54.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下图演示了在一个二维平面上进行梯度下降的过程："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image](http://wp.lampta.com:8000/wp-content/uploads/2022/02/image-55.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下图是三维空间中的梯度下降投射到二维空间"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image](http://wp.lampta.com:8000/wp-content/uploads/2022/02/image-56.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}